<!DOCTYPE html> <html lang="en"> <style> :root { --primary-color: rgba(10, 10, 72, 0.55);; --overlay-color: rgba(24, 39, 51 , 0.85); --menu-speed: 0.75s; } .container-show { max-width: 105rem; margin: auto; overflow: hidden; padding: 0 3rem; } .showcase { background: #fff; height: 90vh; position: relative; } .showcase:before { content: ''; background: #fff; position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: -1; } .showcase .showcase-inner { display: flex; flex-direction: row; align-items: center; justify-content: center; height: 100%; } .showcase h1 { font-size: 8rem; line-height: 1; } .showcase p { font-size: 2rem; } .logo{ font-family: Gotham XNarrow; text-transform: uppercase; } </style> <head> <meta charset="UTF-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <meta name="p:domain_verify" content="24f4001fe32c84cdbe8a07fc24fdeecd"/> <title>Decision Trees in Machine Learning | The Analytics Bay</title> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>Decision Trees in Machine Learning | The Analytics Bay</title> <meta name="generator" content="Jekyll v4.1.1" /> <meta property="og:title" content="Decision Trees in Machine Learning" /> <meta name="author" content="Shivansh Mehendiratta" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="So, in the last blog, we introduced you to the world of Machine Learning; lets dive into a very important aspect of it, that is, ‘Decision Trees’. A tree has many analogies in real life, and it turns out that it has influenced a wide area of machine learning." /> <meta property="og:description" content="So, in the last blog, we introduced you to the world of Machine Learning; lets dive into a very important aspect of it, that is, ‘Decision Trees’. A tree has many analogies in real life, and it turns out that it has influenced a wide area of machine learning." /> <link rel="canonical" href="http://localhost:4000/blog/Decision-Trees/" /> <meta property="og:url" content="http://localhost:4000/blog/Decision-Trees/" /> <meta property="og:site_name" content="The Analytics Bay" /> <meta property="og:image" content="http://localhost:4000/bg.jpeg" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2020-04-18T00:00:00+05:30" /> <meta name="twitter:card" content="summary_large_image" /> <meta property="twitter:image" content="http://localhost:4000/bg.jpeg" /> <meta property="twitter:title" content="Decision Trees in Machine Learning" /> <meta name="twitter:site" content="@shivansh3121" /> <meta name="twitter:creator" content="@shivansh3121" /> <script type="application/ld+json"> {"@type":"BlogPosting","url":"http://localhost:4000/blog/Decision-Trees/","headline":"Decision Trees in Machine Learning","dateModified":"2020-04-18T00:00:00+05:30","datePublished":"2020-04-18T00:00:00+05:30","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/Decision-Trees/"},"author":{"@type":"Person","name":"Shivansh Mehendiratta"},"image":"http://localhost:4000/bg.jpeg","description":"So, in the last blog, we introduced you to the world of Machine Learning; lets dive into a very important aspect of it, that is, ‘Decision Trees’. A tree has many analogies in real life, and it turns out that it has influenced a wide area of machine learning.","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> <link rel="shortcut icon" href="/img/favicon.png"> <link rel="stylesheet" href="/main.css"> <link href='https://olifro.st/feed.xml' rel='alternate' type='application/atom+xml'> <meta name="theme-color" content="#020cfa"> </head> <body> <div class="menu-wrap"> <input type="checkbox" class="toggler"> <div class="hamburger"><div></div></div> <div class="menu"> <div> <div> <ul> <li><a href="/blog">Blog</a></li> <li><a href="/about">About</a></li> <li><a href="/contact">Contact Us</a></li> </ul> </div> </div> </div> </div> <div class="bar container" style="top:0; border-bottom: 5px solid #bb71f8;"><a href="/"><div class="logo" style=" padding: 30px 0;">The Analytics Bay</div></a><ul class="specialul"> <li><a href="/contact">Contact Us</a></li> <li><a href="/about">About</a></li> <li><a href="/blog">Blog</a></li> </ul></div> <main class="content"> <div class="container" style="margin-top: 80px"> <a href="/blog/">← All Posts</a> / <time datetime="2020-04-18T00:00:00+05:30" class="post-date">18 Apr 2020</time> <article class="post"> <h1 class="post-title">Decision Trees in Machine Learning</h1> <p></p> <p class="post-description"><p>So, in the last blog, we introduced you to the world of Machine Learning; lets dive into a very important aspect of it, that is, ‘Decision Trees’. A tree has many analogies in real life, and it turns out that it has influenced a wide area of machine learning.</p> </p> <p><p><img src="/blog/2020-04-18-Decision-Trees/Decision Trees.jpg" alt="Decision Trees" /> Let us first understand; what exactly a decision tree is &amp; it’s working.</p> <p>A decision tree is a type of supervised learning algorithm (having a predefined target variable) which is mostly used in classification problems. It works for both the categorical and continuous input and output variables. In this technique, we split the population or samples into two or more homogeneous sets (or sub-populations) based on most significant splitter/differentiator in input variables.</p> <p>Okay, so all the definition stuff might scare you, so let’s understand this concept with the help of an example.</p> <p>Let us say, we have a sample of 30 students with three variables Gender (Boy/ Girl), Class (IX/ X) and Height (5 to 6 ft). 15 out of these, 30 play cricket in free time. Now, we want to create a model to predict who will play cricket during a leisure period? In this problem, we would need to segregate students who play cricket in their free time based on highly significant input variable among all three.</p> <p>This is where decision tree would help, it will segregate the students based on all values of three variable and identify the variable, which creates the best homogeneous sets of students (which are heterogeneous to each other).</p> <p>In the picture below, you can see that variable Gender is able to identify the best homogeneous sets compared to the height and class.</p> <p>As mentioned above, the decision tree identifies the most significant variable and its value that gives the best homogeneous sets of population.</p> <p>Types of Decision Trees</p> <p>Types of decision tree are based on the type of target variable we have. It can be of two types-</p> <ol> <li> <p>Categorical Variable Decision Tree- Decision Tree which has a categorical target variable is called a categorical variable decision tree. Example- – In the above example of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO.</p> </li> <li> <p>Continuous Variable Decision Tree- If the decision Tree has a continuous target variable then it is called as Continuous Variable Decision Tree.</p> </li> </ol> <p>Now, let’s learn about some important terminologies related to Decision tree based algorithms in Machine Learning, as it will be very important for you to understand these terms if you want to delve deeper into the ‘Decision Trees’.</p> <ol> <li> <p>Root Node- It represents the entire population or samples, and this further gets divided into two or more homogeneous sets.</p> </li> <li> <p>Splitting- It is the process of dividing a node into two or more sub-nodes.</p> </li> <li> <p>Decision Node- When a sub-node splits into further sub-nodes, then it is called a decision node.</p> </li> <li> <p>Leaf/ Terminal Node- Nodes that do not split are called Leaf or Terminal node.</p> </li> <li> <p>Pruning- When we remove sub-nodes of a decision node, the process is called pruning. You can say the opposite process of splitting.</p> </li> <li> <p>Branch / Sub-Tree- A subsection of the entire tree is called branch or sub-tree.</p> </li> </ol> <p>Now, the question which must have come to your mind must be, how and when to make a decision to split a decision tree.</p> <p>The decision of making strategic splits heavily affects a tree’s accuracy. Hence, one has to be really careful while splitting a strategic tree.</p> <p>Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes.</p> <p>The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that the purity of the node increases with respect to the target variable. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.</p> <p>In this we will practically apply one of these algorithms named ‘Gini’; with the help of an example.</p> <p>Gini defines, if we select two items from a population at random, then they must be of the same class, and the probability for this is 1 if the population is pure.</p> <ol> <li> <p>It works with the categorical target variable “Success” or “Failure”.</p> </li> <li> <p>It performs only in Binary splits.</p> </li> <li> <p>Higher the value of Gini, higher would be the homogeneity.</p> </li> </ol> <p>Steps to Calculate Gini for a split</p> <p>Firstly, calculate Gini for sub-nodes, using the formula sum of the square of probability for success and failure (p^2+q^2).</p> <ol> <li>Then, calculate Gini for split using weighted Gini score of each node of that split</li> </ol> <p>Referring to the example used above, where we want to segregate the students based on target variable (playing cricket or not). In the image below, we split the population using two input variables Gender and Class. Now, we would identify which split is producing more homogeneous sub-nodes using Gini.</p> <p>Split on Gender-</p> <ol> <li> <p>Calculate, Gini for sub-node Female = (0.2)<em>(0.2) + (0.8)</em>(0.8) = 0.68</p> </li> <li> <p>Gini for sub-node Male = (0.65)<em>(0.65) + (0.35)</em>(0.35) = 0.55</p> </li> <li> <p>Calculate weighted Gini for Split Gender = (10/30)<em>0.68 + (20/30)</em>0.55 = 0.59</p> </li> </ol> <p>Similar for Split on Class-</p> <ol> <li> <p>Gini for the sub-node Class IX = (0.43)<em>(0.43) + (0.57)</em>(0.57) = 0.51</p> </li> <li> <p>Gini for the sub-node Class X = (0.56)<em>(0.56) + (0.44)</em>(0.44) = 0.51</p> </li> <li> <p>Now we calculate weighted Gini for Split Class = (14/30)<em>0.51 + (16/30)</em>0.51 = 0.51</p> </li> </ol> <p>Above, you can see that Gini score for Split on Gender is higher than Split on Class, hence, the node split will take place on Gender. And since the node will split first in ‘Gender variable’, it is a better and more significant measure for this problem as showcased above with the basic approach of checking homogeneity.</p> <p>So, we hope you have understood the concept of using Decision Trees and usage of Gini to split the root node. Do right your feedback and kindly ask doubts; if you have any</p> </p> <p><strong>Recommended</strong> <a href="/blog/Autocorrelation/">» Autocorrelation </a><br> </p> </article> </div> </main> <!-- <footer id="footer"> <div class="row"> <div class="col-xs-12 col-sm-3 footer-social center-xs"> <small class="social"> <div> <span class="icons"> <a href="https://facebook.com/nucleus.cbs"> <span class="icon icon--instagram"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M22.675 0h-21.35c-.732 0-1.325.593-1.325 1.325v21.351c0 .731.593 1.324 1.325 1.324h11.495v-9.294h-3.128v-3.622h3.128v-2.671c0-3.1 1.893-4.788 4.659-4.788 1.325 0 2.463.099 2.795.143v3.24l-1.918.001c-1.504 0-1.795.715-1.795 1.763v2.313h3.587l-.467 3.622h-3.12v9.293h6.116c.73 0 1.323-.593 1.323-1.325v-21.35c0-.732-.593-1.325-1.325-1.325z"/></svg></span></a> <a href="https://www.linkedin.com/company/nucleus-cbs/"> <span class="icon icon--twitter"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg></span></a> <a href="https://instagram.com/nucleus.cbs"> <span class="icon icon--instagram"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/></svg></span></a> </span> <form action="https://formspree.io/xeqrjbrn" method="POST"> <input type="email" name="replyto" id="Email" placeholder="Mailing List Email" class="email" required> <input type="hidden" name="_next" value="https://nucleuscbs.github.io/thanks/" /> <input type="submit" value="Join"> </form> </div> </small> </div> <div class="col-xs-12 col-sm-6 footer"> <h1 style="color: #fff">Collegiate Entrepreneurs Organisation</h1> <h1>Delhi University</h1> </div> <div class="col-xs-12 col-sm-3 footer"> <a href="/noprivacy/">Privacy Policy</a> | &copy; CEO, Delhi University </div> </div> </footer> --> <footer id="footer" style=" display:grid; grid-template-columns: repeat(20,5%); grid-template-rows: repeat(20,5%); height: 40vh; "> <div class="footer-social footer-layout-social"> <small class="social"> <div> <span class="icons"> <a href="https://facebook.com/nucleus.cbs"> <span class="icon icon--instagram"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M22.675 0h-21.35c-.732 0-1.325.593-1.325 1.325v21.351c0 .731.593 1.324 1.325 1.324h11.495v-9.294h-3.128v-3.622h3.128v-2.671c0-3.1 1.893-4.788 4.659-4.788 1.325 0 2.463.099 2.795.143v3.24l-1.918.001c-1.504 0-1.795.715-1.795 1.763v2.313h3.587l-.467 3.622h-3.12v9.293h6.116c.73 0 1.323-.593 1.323-1.325v-21.35c0-.732-.593-1.325-1.325-1.325z"/></svg></span></a> <a href="https://www.linkedin.com/company/nucleus-cbs/"> <span class="icon icon--twitter"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg></span></a> <a href="https://instagram.com/nucleus.cbs"> <span class="icon icon--instagram"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/></svg></span></a> </span> <form action="https://formspree.io/xeqrjbrn" method="POST"> <input type="email" name="replyto" id="Email" placeholder="Mailing List Email" class="email" required> <input type="hidden" name="_next" value="https://nucleuscbs.github.io/thanks/" /> <input type="submit" value="Join"> </form> </div> </small> </div> <div class="footer-layout-text"> <h1 style="color: #000; margin:0; line-height: 1.2; font-family: Gotham XNarrow;letter-spacing: 0.05rem;">THE ANALYTICS BAY</h1> <img src="/nucleus.png" style="height:50px;width:auto;margin-left:0;"> <!-- <h1 style="line-height: 1.2;font-family: Gotham XNarrow;letter-spacing: 0.05rem; font-size: 3rem;color:#000">Nucleus, the analytics society of SSCBS</h1> --> </div> <div class="footer-layout-copy"> &copy; The Analytics Bay </div> </footer> <script async src=""></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); </script> <!-- Rotator --> </body>
